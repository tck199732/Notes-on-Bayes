{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baye's inference and conjugate prior\n",
    "Baye's theorem tells us that \n",
    "\\begin{equation*}\n",
    "p(\\theta|x) = \\frac{p(x|\\theta)p(\\theta)}{\\int p(x|\\theta)p(\\theta) d\\theta}\n",
    "\\end{equation*}\n",
    "The posterior $p(\\theta|x)$ can be updated after observing each data $x$ provided that the denominator \n",
    "on the RHS is tractable. This is only valid when the prior $p(\\theta)$ and posterior $p(\\theta|x)$ come from the same parametric family. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, consider a dice roll problem. Let $X = \\set{x_1, x_2, \\cdots, x_N}$ be N independent dice rolls. Suppose there are K possible outcomes $\\set{1,2,\\cdots,K}$ for each dice so that the number of outcome k can be written as $N_k = \\sum_{i=1}^N \\mathbf{I}(x_i=k)$. The likelihood has the form \n",
    "\n",
    "\\begin{equation*}\n",
    "p(x|\\theta) = \\prod_{k=1}^K\\theta_k^{N_k}\n",
    "\\end{equation*}\n",
    "where $p(x_i=k) = \\theta_k$ is the probability of outcome k, which is subject to constraint $\\sum_{k=1}^K\\theta_k = 1$. If we choose the prior to be Dirichlet distribution, \n",
    "\\begin{equation*}\n",
    "p(\\theta) = Dir(\\theta|\\alpha) = \\frac{1}{B(\\alpha_1,\\cdots, \\alpha_K)}\\prod_{k=1}^K \\theta_k^{\\alpha_k- 1}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then by Baye's theroem, the posterior $p(\\theta|x)$ is proportional to \n",
    "\\begin{equation*}\n",
    "p(x|\\theta)p(\\theta) = \\frac{1}{B(\\alpha_1,\\cdots, \\alpha_K)}\\prod_{k=1}^K \\theta_k^{N_k+\\alpha_k- 1}\n",
    "\\end{equation*}\n",
    "where $\\alpha_k' = \\alpha_k+N_k$ for all k. We see that the prior and posterior are both Dirichlet distribution only with different parameterization. We call $Dir(\\theta|\\alpha)$ the conjugate prior of the multinomial likelihood defined above. The posterior can only be derived analytically if the prior and posterior are conjugate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, the Dirichlet distribution can be normalized by changing the $\\alpha$ to $\\alpha + N$. Hence,\n",
    "\\begin{equation*}\n",
    "p(\\theta|x,\\alpha) = \\frac{1}{B(\\alpha_1+N_1,\\cdots, \\alpha_K+N_K)} \\prod_{k=1}^K \\theta^{N_k+\\alpha_k-1} = Dir(\\theta|\\alpha')\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the expectation of Dirichlet distribution is \n",
    "\\begin{equation*}\n",
    "\\mathbb{E}_{Dir(\\theta,\\alpha)} \\theta_k = \\frac{\\alpha_l}{\\sum_{l=1}^K \\alpha_l}\n",
    "\\end{equation*}\n",
    "\n",
    "The expectation of the posterior is \n",
    "\\begin{equation*}\n",
    "\\mathbb{E}_{p(\\theta|x,\\alpha)} \\theta_k = \\frac{\\alpha_k + N_k}{\\sum_{l=1}^K \\alpha_l+N_l}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conclusion is that we can only obtain a closed form of the posterior if there is conjugacy. Should we have use a different prior, it will be difficult to calculate the normalization (denominator of Baye's theorem) and numerical method would be necessary. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d3cd1669c9bd0bc4a10448fec43c91475e59e3af6819e48dac91adb18c81ad3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
